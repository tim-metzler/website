---
title: Solving a classification problem in R
author: Tim Metzler
date: '2023-03-03'
slug: solving-a-classification-problem-in-r
categories: []
tags: []
subtitle: 'Data Scientist Associate Practical Exam'
summary: 'In this project binomial logistic regression and a random forest model will be used to solve a classification problem in R'
authors: []
lastmod: '2023-03-03T19:07:18+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      include = F,
                      message = F, 
                      warning = F,
                      results = "hide")
```

# Background given by Datacamp
This project was part of the Datacamp certification with the following background given:

EMO is a manufacturer of electric motorcycles.
EMO launched its first electric motorcycle in India in 2019.
The product team has been asking website users to rate the motorcycles.
Ratings from owners help the product team to improve the quality of the motorcycles.
Ratings from non-owners help the product team add new features. 
They hope the new features will increase the number of new customers.
The product team wants to extend the survey. But, they want to be sure they can predict whether the ratings came from owners or non-owners.

```{r libraries}
# load libraries
library(ggplot2)
#install.packages("randomForest")
library(randomForest)
library(caTools)
library(dplyr)
```

```{r data}
# read data
#data = read.csv("https://s3.amazonaws.com/talent-assets.datacamp.com/electric_bike_ratings_2212.csv")
data = read.csv("electric_bike_ratings_2212.csv")
```

## Data validation
I started the analysis by making sure that the data fits the criteria:

1. _owned_: Has only values of "0" and "1" with no missing values. Fits the criteria. Was converted to factor.
2. _make_model_: Fits the description with no missing values.
3. _review_month_: Some observations had not only the month but also the day included, removed everything but the shortened name of the month. No missing values.
4. _web_browser_: Replaced 150 missing values with "unknown". Other values fit the description.
5. _reviewer_age_: Replaced 105 missing values with mean age and converted from character to integer.
6. _primary_use_: No missing values, fits description.
7. _value_for_money_: Was given as a string including "/10". Removed that part and converted the remaining number indicating the rating to integer. No missing values.
8. _overall_rating_: Values are within range without missing values, fit the description as is.

```{r validation}
### check whether values fit description ###
#owned
sum(is.na(data$owned))
range(data$owned)
unique(data$owned)
data$owned = as.factor(data$owned)

# only values of 1 or one, no missings. Fits the description.

#make_model
sum(is.na(data$make_model))
unique(data$make_model)
class(data$make_model)
# Six possible values that fit the description. No missing values in the data.

#review_month
sum(is.na(data$review_month))
unique(data$review_month)

data$reviewmonth = gsub("[[:digit:]]", "", data$review_month)
data$reviewmonth = gsub("-", "", data$reviewmonth)
unique(data$reviewmonth)
data$review_month = data$reviewmonth
# Some observations had the day and the month saved, removed everything but the 
# short Month from strings 
# now 12 months, no missings

#web_browser
sum(is.na(data$web_browser))
unique(data$web_browser)
data$web_browser = ifelse(is.na(data$web_browser), "unknown", data$web_browser)
# replaced 150 missing values with "unknown". Other values fit the given labels.

#reviewer_age
sum(is.na(data$reviewer_age)) # no missings
unique(data$reviewer_age) # some missings coded as "-"
class(data$reviewer_age) # class is character

data$reviewer_age = ifelse(data$reviewer_age == "-", NA, data$reviewer_age)
#105 NA
data$reviewer_age = as.numeric(data$reviewer_age)
data$reviewer_age = ifelse(is.na(data$reviewer_age), mean(data$reviewer_age, na.rm =T), data$reviewer_age)
data$reviewer_age = as.integer(data$reviewer_age)
# replaced missing with mean

#primary_use
unique(data$primary_use)
sum(is.na(data$primary_use))
# no missings, only two unique values of "Commuting" and "Leisure" as expected.

#value_for_money
unique(data$value_for_money)
data$value_for_money = gsub("/10", "", data$value_for_money)
class(data$value_for_money)
data$value_for_money = as.integer(data$value_for_money)
# rating was given as character strings including "/10", that part was deleted 
# and the remaining number converted from character type to numeric 

#overall_rating
unique(data$overall_rating)
range(data$overall_rating)
class(data$overall_rating)
sum(is.na(data$overall_rating))
#values are within range and no missing values. nothing changed.
```

## Visualization of ownership
As seen in Graph 1 most reviews (890) are from people who own the reviewed moped, while there are fewer reviews from people not owning the reviewed moped (610). There are roughly 1.46 times as many reviews from owners than form non-owners. While this is a bit unbalanced there are still enough observations in both categories to not do anything about the imbalance. 

```{r graph1, include = T}
ggplot(data, aes(x = owned)) +
  geom_bar() +
  geom_text(aes(label=after_stat(count)), stat = "count", vjust = 1.5, colour = "white") +
  xlab("Reviewer owns moped") +
  scale_x_discrete(labels=c("no", "yes")) +
  ggtitle("Graph 1")
```

## Distribution of overall rating
As visualized in Graph 2, the distribution of _overall rating_ is a multimodal distribution with three main peaks at around 12.25, 15.5 and 18.5. The mean of the distribution is 17.14 and the standard derivation 2.45.

```{r graph2, include = T}
ggplot(data, aes(x = overall_rating))+
  geom_histogram(colour="black", fill="white", bins = 30) +
#  geom_vline(aes(xintercept=mean(overall_rating, na.rm=T)),   # Ignore NA values for mean
 #            color="red", linetype="dashed", size=1) +
  scale_x_continuous(breaks = 1:30) +
  xlab("overall rating")+ 
  ggtitle("Graph 2")

#mean(data$overall_rating)
#sd(data$overall_rating)
```

## The relationship between overall rating and ownership
The relationship between overall rating and ownership can be seen in Graph 3. The reviews from owners are on average higher than those of non-owners and the interquartile range of overall rating by owners is lower than the interquartile range of overall rating by non-owners. There are some outliers but I don't see a justification for excluding them from further analysis.

```{r graph3, include = T}
ggplot(data, aes(owned, overall_rating)) +
  geom_boxplot() +
  xlab("Reviewer owns moped") +
  scale_x_discrete(labels=c("no", "yes")) +
  scale_y_continuous(breaks = 1:30) +
  ylab("overall rating") +
ggtitle("Graph 3")
```

## What type of machine learning problem?
The business wants to predict whether a review came from an owner or not using the
data provided. This is a binary classification problem.


## Fitting a baseline model
Before fitting a baseline model, I will split the data into a test and training data set. Then I will fit a logistic regression model as a baseline model.

```{r logreg, echo = T}
#######################################################
############# creating test and train data sets #######
#######################################################
set.seed(101)
sample = sample.split(data[,1], SplitRatio = .75)
train = subset(data, sample == T)
test = subset(data, sample == F)

#######################################################
########### Task 6: fitting baseline model ############
#######################################################

model.baseline = glm(owned ~ make_model 
                     + review_month
                     + web_browser
                     + reviewer_age
                     + primary_use
                     + value_for_money
                     + overall_rating,
                     family = "binomial",
                     data = train)

# summary(model.baseline)
```

## Fitting a comparison model
After the baseline model a random forest model is implemented as a comparison model.

```{r randomforest, echo = T}
model.randomForest = randomForest(owned ~ make_model 
                                  + review_month
                                  + web_browser
                                  + reviewer_age
                                  + primary_use
                                  + value_for_money
                                  + overall_rating, data = train, ntrees = 1000)
#summary(model.randomForest)
```

## Why those models?
I choose a binomial logistic regression as a baseline model and a random forest model as a comparison model. Both models are suitable for classification problems, i.e. the type of problem we have to solve here. The binomial logistic regression model was chosen because it is fast and easy to interpret. The advantage of the random forest model is that it is better suited for non-linearities as well as data containing many features and a large number of observations.

## Comparing model performance
To compare the performance of both models I compare the acuracy of both models, i.e. the proportion of correct predictions of all predictions, because that measure is easy to interpret. The acuracy of the baseline model is 74%, while the acuracy of the random forest model is 72%. This means that the baseline model performs better on the given data in the sense that it makes more correct predictions. 

```{r modelcomp, echo = T}
#prediction using baseline mode
test$pred.baseline = predict(model.baseline, test, type = "response")
#predict 1 if predicted probability is > 0.5
test$pred.baseline = ifelse(test$pred.baseline > 0.5, 1, 0)
#proportion of correctly predicted ownership
mean(test$pred.baseline == test$owned)


# prediction using random Forest
test$pred.randomForest = predict(model.randomForest, test, type = "class")
# proportion of correctly predicted ownership
mean(test$pred.randomForest == test$owned)
```

## Which model is better?
The random forest model performs worse than the baseline logistic regression model if we look at the acuracy of both models. As stated earlier the random forest approach is a better choice for non-linear relations as well as data sets with many features and observations. That the model did worse than the logistic regression model could be a sign of the relation being in fact linear, as assumed in the logistic regression approach. There are also not that many features in the data, so the random forest algorithm could not use it's strength there.